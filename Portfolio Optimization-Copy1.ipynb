{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eb45b889-f0f0-4ca6-ae76-a74ea0b7ea49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "import pandas as pd\n",
    "from pypfopt import expected_returns, risk_models, BlackLittermanModel, EfficientFrontier\n",
    "import yfinance as yf\n",
    "import talib\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7c6963-1a55-4d54-8ece-7485f810857f",
   "metadata": {},
   "source": [
    "# <u>Portfolio Optimisation</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e9e2e8-2839-4405-b6f3-1d932b135481",
   "metadata": {},
   "source": [
    "https://theaiquant.medium.com/mastering-complete-portfolio-optimization-with-mean-variance-analysis-in-python-4d78c5e7a688"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570e7ffd-7c29-49da-b685-3b2b88514ae9",
   "metadata": {},
   "source": [
    "This notebook will look at creating an optimal portfolio of assets that maximises return for a given level of risk.\n",
    "\n",
    "A optimisation model will be created using techniques including Machine Learning, Black-Litterman Model, and Monte Carlo Simulations alongside traditional Mean-Variance Optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79a4ca2-dae9-47ad-8a4f-1cc5a94a6f5d",
   "metadata": {},
   "source": [
    "## A. Portfolio Optimisation using Traditional Mean-Variance Optimization (Markowitz Modern Portfolio Theory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca18926-947f-47b3-b9f1-f830d090a49d",
   "metadata": {},
   "source": [
    "Traditional Methods of Portfolio optimisation\n",
    "\n",
    "Harry Markowitz modern portfolio theory, which uses mean-variance optimiation to minimizes risk (variance) for a given return. Optimizes the portfolio's asset weights based on expected returns and the covariance matrix of returns.\n",
    "\n",
    "To do this scipy's optimize function is used to maximise the sharpe-ratio (which is the return to risk ratio)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e28ce57-82d2-408b-84c0-cae7ea47ef75",
   "metadata": {},
   "source": [
    "### Step 1: Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a44f393-64dd-4470-bed9-3bf6e305c0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  8 of 8 completed\n"
     ]
    }
   ],
   "source": [
    "assets = ['BARC.L', 'BP', 'GOOGL', 'LLOY.L', 'META','SHEL', 'VOD', 'VUSA.AS']\n",
    "data = yf.download(assets, start=\"2015-01-01\", end=\"2024-01-01\")['Adj Close']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9486038-08f8-428d-9744-66685d425e3a",
   "metadata": {},
   "source": [
    "Using a time frame of around 10 years to reflect Long-term perspective of asset behaviours and modelling over this timeframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "af539c57-ae33-49cf-b070-ecab46ba3209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values (forward-fill and backward-fill)\n",
    "data = data.ffill().bfill()\n",
    "\n",
    "# Calculating the log returns benefits include: time additive, allow for easier aggregation of returns across periods.\n",
    "returns = np.log(data / data.shift(1))\n",
    "\n",
    "# Compute mean returns and covariance matrix\n",
    "mean_returns = returns.mean()\n",
    "cov_matrix = returns.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd353c05-8c2b-4f26-80f7-68205e0e1aac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define portfolio return and volatility functions\n",
    "def portfolio_performance(weights, mean_returns, cov_matrix):\n",
    "    portfolio_return = np.sum(weights * mean_returns)\n",
    "    portfolio_volatility = np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "    return portfolio_return, portfolio_volatility\n",
    "\n",
    "# Objective function (maximize Sharpe ratio)\n",
    "def negative_sharpe_ratio(weights, mean_returns, cov_matrix, risk_free_rate=0.03):\n",
    "    p_ret, p_volatility = portfolio_performance(weights, mean_returns, cov_matrix)\n",
    "    return -(p_ret - risk_free_rate) / p_volatility\n",
    "\n",
    "# Constraints (weights sum to 1)\n",
    "def check_sum(weights):\n",
    "    return np.sum(weights) - 1\n",
    "\n",
    "# Bounds for weights (each weight between 0 and 1)\n",
    "bounds = tuple((0, 1) for asset in range(len(assets)))\n",
    "\n",
    "# Initial guess (equal weight distribution)\n",
    "initial_weights = len(assets) * [1. / len(assets)]\n",
    "\n",
    "# Optimize\n",
    "constraints = ({'type': 'eq', 'fun': check_sum})\n",
    "result = minimize(negative_sharpe_ratio, initial_weights, args=(mean_returns, cov_matrix),\n",
    "                  method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "optimal_weights = result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3711aba6-a551-4af5-b9e3-e14cea744bc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 9.34297084e-12, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 5.94164561e-12, 0.00000000e+00, 0.00000000e+00])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_weights\n",
    "# sum(optimal_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "068a278c-0336-478c-b1a9-bbfacd532c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial guess (equal weight distribution)\n",
    "initial_weights = len(assets) * [1. / len(assets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dab94be5-0714-4190-9107-6e51e62fa683",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125, 0.125]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b93ad136-446a-40c9-a83b-da102e86c53e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Ticker        Weight\n",
      "0   BARC.L  1.000000e+00\n",
      "1       BP  9.342971e-12\n",
      "5     SHEL  5.941646e-12\n",
      "2    GOOGL  0.000000e+00\n",
      "3   LLOY.L  0.000000e+00\n",
      "4     META  0.000000e+00\n",
      "6      VOD  0.000000e+00\n",
      "7  VUSA.AS  0.000000e+00\n"
     ]
    }
   ],
   "source": [
    "# DataFrame to display tickers and their corresponding optimal weights\n",
    "weights_df = pd.DataFrame({\n",
    "    'Ticker': assets,\n",
    "    'Weight': optimal_weights\n",
    "})\n",
    "weights_df = weights_df.sort_values(by='Weight', ascending=False)\n",
    "print(weights_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b317da08-e520-4d2d-9248-7b657096554b",
   "metadata": {},
   "source": [
    "## B. Portfolio Optimisation using Black-Litterman Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c46b18-f833-49c1-9722-5961924b402a",
   "metadata": {},
   "source": [
    "Black-Litterman Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db8a020-4c35-4fa4-b09f-187e8b23b743",
   "metadata": {},
   "source": [
    "Black-Litterman model is used to optimise asset allocation within an investorâ€™s risk tolerance and market views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97bd162a-104d-4f14-8e2c-13d597d64791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market cap not available for VUSA.AS\n",
      "Market Capitalizations:\n",
      "BARC.L: 38446784512\n",
      "BP: 76128632832\n",
      "GOOGL: 2080344375296\n",
      "LLOY.L: 32299640832\n",
      "META: 1436939714560\n",
      "SHEL: 198653181952\n",
      "VOD: 23172112384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[38446784512,\n",
       " 76128632832,\n",
       " 2080344375296,\n",
       " 32299640832,\n",
       " 1436939714560,\n",
       " 198653181952,\n",
       " 23172112384]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Calculate expected returns and covariance matrix\n",
    "mu = expected_returns.mean_historical_return(data)\n",
    "S = risk_models.sample_cov(data)\n",
    "\n",
    "# 2. Define market equilibrium returns (pi)\n",
    "# The market caps are required in the model as it helps calculate the market-implied equilibriums returns.\n",
    "# The returns of which represent the prior belief. \n",
    "\n",
    "# Define your stock tickers\n",
    "tickers = ['BARC.L', 'BP', 'GOOGL', 'LLOY.L', 'META','SHEL', 'VOD', 'VUSA.AS']\n",
    "\n",
    "# Fetch market cap data\n",
    "market_caps = {}\n",
    "for ticker in tickers:\n",
    "    stock = yf.Ticker(ticker)\n",
    "    try:\n",
    "        market_cap = stock.info[\"marketCap\"]  # Market capitalization\n",
    "        market_caps[ticker] = market_cap\n",
    "    except KeyError:\n",
    "        print(f\"Market cap not available for {ticker}\")\n",
    "\n",
    "market_capss = []\n",
    "# Print market caps\n",
    "print(\"Market Capitalizations:\")\n",
    "for ticker, cap in market_caps.items():\n",
    "    print(f\"{ticker}: {cap}\")\n",
    "    market_capss.append(cap)\n",
    "\n",
    "market_capss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d8815cbe-80b6-4fee-9711-810d6b82a19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected Market Return: 0.11829804390813935\n",
      "Market Variance: 0.030681580979339276\n",
      "Annual Risk-Free Rate: 0.10792757349171224\n",
      "Estimated Risk Aversion: 0.34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Instead of using the default risk aversion below. We can estimate risk aversion using historical data as follows:\n",
    "\n",
    "# Example tickers (representing the market)\n",
    "market_ticker = \"^GSPC\"  # S&P 500 as a proxy for market portfolio\n",
    "risk_free_ticker = \"^TNX\"  # 10-year Treasury Yield data (proxy for risk-free rate)\n",
    "\n",
    "# Download historical data for market (e.g., S&P 500) and risk-free rate (e.g., 13-week Treasury bill)\n",
    "market_data = yf.download(market_ticker, start=\"2010-01-01\", end=\"2024-01-01\")['Adj Close']\n",
    "risk_free_data = yf.download(risk_free_ticker, start=\"2010-01-01\", end=\"2024-01-01\")['Adj Close'] / 100  # Convert to percentage\n",
    "\n",
    "# Calculate daily returns for market and risk-free rate\n",
    "market_returns = market_data.pct_change().dropna()\n",
    "risk_free_rate = risk_free_data.pct_change().dropna()\n",
    "\n",
    "# Calculate the expected market return (annualized)\n",
    "expected_market_return = market_returns.mean() * 252  # Annualize by multiplying by 252 trading days\n",
    "print(f\"Expected Market Return: {expected_market_return}\")\n",
    "\n",
    "# Calculate the variance of the market portfolio (annualized)\n",
    "market_variance = market_returns.var() * 252  # Annualize by multiplying by 252 trading days\n",
    "print(f\"Market Variance: {market_variance}\")\n",
    "\n",
    "# Risk-free rate (annualized)\n",
    "annual_risk_free_rate = risk_free_rate.mean() * 252\n",
    "print(f\"Annual Risk-Free Rate: {annual_risk_free_rate}\")\n",
    "\n",
    "# Estimate risk aversion (using Sharpe ratio approach)\n",
    "risk_aversion = (expected_market_return - annual_risk_free_rate) / market_variance\n",
    "print(f\"Estimated Risk Aversion: {risk_aversion:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4e4d83-630f-4233-bf02-e0c4e080afb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to define investor views which are done using arrays P and Q\n",
    "# To get investor views. We will use technical analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ed6fa85d-83b9-4ff2-95a8-52b9a9703306",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  8 of 8 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BARC.L': 59.041509898650844, 'BP': 42.94519755590237, 'GOOGL': 47.15540912945262, 'LLOY.L': 37.58538617929556, 'META': 52.06967751444282, 'SHEL': 41.56169889792674, 'VOD': 47.93092059304563, 'VUSA.AS': 72.52363193797451}\n",
      "{'BARC.L': -0.19092101374566273, 'BP': 0.11450634437948692, 'GOOGL': -1.4909294455657338, 'LLOY.L': 0.03896296516210129, 'META': -1.0401933129860177, 'SHEL': -0.0542031102300643, 'VOD': 0.03864660473723286, 'VUSA.AS': 0.14567996167239494}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Fetch market data\n",
    "# tickers = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\"]\n",
    "tickers = ['BARC.L', 'BP', 'GOOGL', 'LLOY.L', 'META','SHEL', 'VOD', 'VUSA.AS']\n",
    "data = yf.download(tickers, start=\"2023-01-01\", end=\"2024-11-27\")[\"Adj Close\"]\n",
    "data = data.ffill().dropna()\n",
    "\n",
    "# Calculate RSI and MACD for each ticker\n",
    "rsi_values = {}\n",
    "macd_values = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    prices = data[ticker]\n",
    "    \n",
    "    # Calculate RSI using TA-Lib\n",
    "    rsi = talib.RSI(prices, timeperiod=14)\n",
    "    rsi_values[ticker] = rsi.iloc[-1]  # Most recent RSI value\n",
    "    \n",
    "    # Calculate MACD using TA-Lib\n",
    "    macd, macd_signal, macd_hist = talib.MACD(\n",
    "        prices, \n",
    "        fastperiod=12, \n",
    "        slowperiod=26, \n",
    "        signalperiod=9\n",
    "    )\n",
    "    macd_values[ticker] = macd_hist.iloc[-1]  # Most recent MACD histogram value\n",
    "\n",
    "print(rsi_values)\n",
    "print(macd_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b84ed8d-1fc7-4228-b30b-0c62189f5d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('BARC.L', 'bearish'),\n",
       " ('BP', 'bullish'),\n",
       " ('GOOGL', 'bearish'),\n",
       " ('LLOY.L', 'bullish'),\n",
       " ('META', 'bearish'),\n",
       " ('SHEL', 'bearish'),\n",
       " ('VOD', 'bullish')]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "views = []  # List to store views\n",
    "for ticker in tickers:\n",
    "    if rsi_values[ticker] < 70 and macd_values[ticker] > 0:\n",
    "        views.append((ticker, \"bullish\"))\n",
    "    elif rsi_values[ticker] > 30 and macd_values[ticker] < 0:\n",
    "        views.append((ticker, \"bearish\"))\n",
    "\n",
    "views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "da18f74e-5cb8-4298-ac13-21eb8672939c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P Matrix:\n",
      "[[-1  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  0  0]\n",
      " [ 0  0 -1  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0]\n",
      " [ 0  0  0  0 -1  0  0  0]\n",
      " [ 0  0  0  0  0 -1  0  0]\n",
      " [ 0  0  0  0  0  0  1  0]]\n",
      "\n",
      "Q Vector:\n",
      "[-0.05  0.08 -0.05  0.08 -0.05 -0.05  0.08]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Initialize P and Q\n",
    "P = []\n",
    "Q = []\n",
    "\n",
    "# Define expected return assumptions\n",
    "bullish_return = 0.08  # Example: 8% expected return for bullish views\n",
    "bearish_return = -0.05  # Example: -5% expected return for bearish views\n",
    "\n",
    "# Populate P and Q based on views\n",
    "for view in views:\n",
    "    row = [0] * len(tickers)  # Initialize row for P\n",
    "    ticker, sentiment = view\n",
    "    idx = tickers.index(ticker)  # Get index of the ticker in tickers\n",
    "    \n",
    "    if sentiment == \"bullish\":\n",
    "        row[idx] = 1  # +1 for bullish view\n",
    "        Q.append(bullish_return)\n",
    "    elif sentiment == \"bearish\":\n",
    "        row[idx] = -1  # -1 for bearish view\n",
    "        Q.append(bearish_return)\n",
    "    \n",
    "    P.append(row)\n",
    "\n",
    "P = np.array(P)\n",
    "Q = np.array(Q)\n",
    "\n",
    "print(\"P Matrix:\")\n",
    "print(P)\n",
    "print(\"\\nQ Vector:\")\n",
    "print(Q)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d2457589-4b54-4a5a-8d82-af893bab20b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected annual return: 5.2%\n",
      "Annual volatility: 22.5%\n",
      "Sharpe Ratio: 0.14\n",
      "Optimized Weights: OrderedDict({'BARC.L': 0.0, 'BP': 0.26124, 'GOOGL': 0.01512, 'LLOY.L': 0.26091, 'META': 0.07004, 'SHEL': 0.0, 'VOD': 0.3927, 'VUSA.AS': 0.0})\n"
     ]
    }
   ],
   "source": [
    "# 4. Initialize the Black-Litterman model\n",
    "bl = BlackLittermanModel(S, Q=Q, P=P, market_caps=market_caps, risk_aversion=0.34)\n",
    "\n",
    "# 5. Get adjusted returns and covariance matrix\n",
    "bl_return = bl.bl_returns()\n",
    "bl_cov = bl.bl_cov()\n",
    "\n",
    "# 6. Optimize portfolio using Black-Litterman outputs\n",
    "ef = EfficientFrontier(bl_return, bl_cov)\n",
    "weights = ef.max_sharpe()\n",
    "cleaned_weights = ef.clean_weights()\n",
    "ef.portfolio_performance(verbose=True)\n",
    "\n",
    "print(\"Optimized Weights:\", cleaned_weights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
